name: neus-sl-blur-${dataset.capture_id}-${dataset.scene}-Supp
tag: a1-${system.loss.alpha1}_a2-${system.loss.alpha2}_Back-${model.back_rendering}_avg-${dataset.avg_itr}_normal-${model.use_normal}
seed: 42

dataset:
  category: captured-geoalbamb
  opengl: False
  noise: False
  denoise: False
  name: sl
  scene_object: david
  capture_id: david
  num_patterns: 3
  family_patterns: opt0
  freq_patterns: 128
  scene: ${dataset.scene_object}_${dataset.family_patterns}_n${dataset.num_patterns}_f${dataset.freq_patterns}
  gt_scene: ${dataset.scene_object}_opt0_n30_f32
  root_dir: ../data/captured_data/${dataset.capture_id}/${dataset.scene}
  gt_dir: ../data/captured_data/${dataset.capture_id}/${dataset.gt_scene}
  avg_itr: 1

  img_downscale: 1 # specify training image size by either img_wh or img_downscale
  near_plane: 2.0
  far_plane: 6.0
  spheric_poses: false
  use_pixel_centers: true
  train_split: 'train'
  val_split: 'val'
  test_split: 'test'
  camera_angle_x: 0.6911112070083618

model:
  opengl: ${dataset.opengl}
  name: neus-geometry-albedo-ambient-wz-camproblur
  radius: 1.5
  back_rendering: false
  use_normal: true
  num_samples_per_ray: 1024
  train_num_rays: 256
  max_train_num_rays: 8192
  grid_prune: true
  grid_prune_occ_thre: 0.001
  dynamic_ray_sampling: true
  batch_image_sampling: true
  randomized: true
  ray_chunk: 4096
  cos_anneal_end: 20000
  learned_background: false
  background_color: black
  variance:
    init_val: 0.3
    modulate: false
  geometry:
    name: volume-sdf
    radius: ${model.radius}
    feature_dim: 1
    grad_type: analytic
    isosurface:
      method: mc
      resolution: 512
      chunk: 2097152
      threshold: 0.
    xyz_encoding_config:
      otype: HashGrid
      n_levels: 16
      n_features_per_level: 2
      log2_hashmap_size: 19
      base_resolution: 16
      per_level_scale: 1.447269237440378
      include_xyz: true
    mlp_network_config:
      otype: VanillaMLP
      activation: ReLU
      output_activation: none
      n_neurons: 64
      n_hidden_layers: 2
      sphere_init: false
      sphere_init_radius: 0.5
      weight_norm: true

  albedo:
    name: 2d-implicit-albedo
    n_input_dim: 2
    n_output_dim: 1
    xyz_encoding_config:
      otype: HashGrid
      n_levels: 16
      n_features_per_level: 2
      log2_hashmap_size: 15
      base_resolution: 16
      per_level_scale: 1.447269237440378
    mlp_network_config:
      otype: FullyFusedMLP
      activation: ReLU
      output_activation: sigmoid
      n_neurons: 64
      n_hidden_layers: 2

  ambient:
    name: 2d-implicit-ambient
    n_input_dim: 2
    n_output_dim: 1
    xyz_encoding_config:
      otype: HashGrid
      n_levels: 16
      n_features_per_level: 2
      log2_hashmap_size: 15
      base_resolution: 16
      per_level_scale: 1.447269237440378
    mlp_network_config:
      otype: FullyFusedMLP
      activation: ReLU
      output_activation: sigmoid
      n_neurons: 64
      n_hidden_layers: 2

  blur:
    projector_blur_flag: true
    name: 2d-projector-kernel-wz-center
    in_channel: ${dataset.num_patterns}
    kernel_size: 11
    blurstart: 1000
    normalize: 0
    blurprojectorside: 1



system:
  name: neus-sl-system-geometry-albedo-ambient-wz-camproblur
  loss:
    lambda_rgb_mse: 10.
    lambda_rgb_l1: 1
    lambda_mask: 0.1
    lambda_eikonal: 0.1
    lambda_sparsity: 0.01
    sparsity_scale: 1.0
    alpha1: 1 # camera loss
    alpha2: 1 # projector loss

  optimizer:
    name: Adam
    args:
      lr: 0.001
      betas: [0.9, 0.99]
      eps: 1.e-15
    params:
      geometry:
        lr: 0.0008
      variance:
        lr: 0.0008
      albedo:
        lr: 0.008
      ambient:
        lr: 0.008
      blur:
        lr: 0.008

  warmup_steps: 500
  scheduler:
    name: SequentialLR
    interval: step
    milestones:
      - ${system.warmup_steps}
    schedulers:
      - name: LinearLR # linear warm-up in the first system.warmup_steps steps
        args:
          start_factor: 0.01
          end_factor: 1.0
          total_iters: ${system.warmup_steps}
      - name: ExponentialLR
        args:
          gamma: ${calc_exp_lr_decay_rate:0.1,${sub:${trainer.max_steps},${system.warmup_steps}}}

checkpoint:
  save_top_k: -1
  every_n_train_steps: ${trainer.max_steps}

trainer:
  max_steps: 10000
  log_every_n_steps: 50
  num_sanity_val_steps: -1
  val_check_interval: 2000
  limit_train_batches: 1.0
  limit_val_batches: 2.0
  enable_progress_bar: true
  precision: 32